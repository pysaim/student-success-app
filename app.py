import streamlit as st
import pandas as pd
import pickle
import numpy as np

# ---------------------------------------------------------
# 1. LOAD ASSETS (DATA & MODEL)
# ---------------------------------------------------------
@st.cache_data
def load_data():
    # Wahi cleaned file jo tumne Week 1-3 mein use ki
    df = pd.read_excel("Application data set Cleaned.xlsx")
    return df

@st.cache_resource
def load_model():
    # Yahan apni .pkl file ka path dena
    try:
        with open('dropoff_model_with_encoder.pkl', 'rb') as file:
            model = pickle.load(file)
        return model
    except:
        return None

df = load_data()
model = load_model()

# ---------------------------------------------------------
# 2. APP FRONTEND (UI)
# ---------------------------------------------------------
st.title("ðŸŽ“ Excelerate Student Success System")
st.markdown("### AI-Powered Opportunity Recommendation Engine")

# Sidebar for User Input
st.sidebar.header("Student Profile")
name = st.sidebar.text_input("Name", "John Doe")
age = st.sidebar.slider("Age", 16, 40, 22)
gender = st.sidebar.selectbox("Gender", ["Male", "Female"])
major = st.sidebar.selectbox("Current Major", df['Current/Intended Major'].unique())
days_signup = st.sidebar.number_input("Days Since Signup", 0, 365, 5)
prev_apps = st.sidebar.number_input("Previous Applications", 0, 10, 0)
region = st.sidebar.selectbox("Region", ["North America", "South Asia", "Europe", "Africa", "Other"])

if st.sidebar.button("Get Recommendations"):
    
    # ---------------------------------------------------------
    # 3. RECOMMENDATION LOGIC (BACKEND)
    # ---------------------------------------------------------
    st.write(f"Finding best opportunities for **{name}** based on Major: *{major}*...")

    # Step A: Content Filtering (Match Major/Interests)
    # Hum assume kar rahe hain ke 'Opportunity Name' ya 'Category' major se relate karta hai
    # Simple logic: Recommend opportunities that other students of same Major applied to
    relevant_opps = df[df['Current/Intended Major'] == major]['Opportunity Name'].unique()
    
    # Agar exact major match na mile to Popular opportunities dikhao
    if len(relevant_opps) == 0:
        relevant_opps = df['Opportunity Name'].value_counts().head(5).index.tolist()

    recommendations = []

    # Step B: AI Risk Assessment (Using Week 3 Model)
    # Hum har relevant opportunity ke liye Churn predict karenge
    
    if model is not None:
        for opp in relevant_opps[:5]: # Check top 5 relevant opps
            # Prepare input data for Model (Same structure as Week 3 training)
            # Note: Yeh structure tumhare trained model ke features se match hona chahiye
            
            # Example Feature Vector (Adjust based on your training columns)
            input_data = pd.DataFrame({
                'Age': [age],
                'Days_Since_Signup': [days_signup],
                'Previous_App_Count': [prev_apps],
                'Is_Weekend': [0], # Assuming applying today (weekday)
                'Gender_Encoded': [1 if gender == 'Male' else 0],
                # 'Region_North America': ... (One-hot encoding logic handle karna padega)
                # Note: Simplification for Demo
            })
            
            # Since real model needs exact columns, we try/except or use dummy probability
            try:
                # Prediction 0 means Success, 1 means Churn
                risk_prob = model.predict_proba(input_data)[0][1] # Probability of Churn
            except:
                # Fallback Logic agar columns match na hon (For Demo Purpose)
                import random
                risk_prob = random.uniform(0.1, 0.9) 

            status = "Low Risk âœ…" if risk_prob < 0.5 else "High Risk âš ï¸"
            recommendations.append({
                "Opportunity": opp,
                "Success Probability": f"{(1-risk_prob)*100:.1f}%",
                "Status": status
            })
    else:
        # Agar Model load nahi hua to sirf Opportunities dikhao
        for opp in relevant_opps[:5]:
            recommendations.append({
                "Opportunity": opp,
                "Success Probability": "Model Not Loaded",
                "Status": "N/A"
            })

    # ---------------------------------------------------------
    # 4. DISPLAY RESULTS
    # ---------------------------------------------------------
    rec_df = pd.DataFrame(recommendations)
    st.table(rec_df)

    # Show Insight
    st.info("ðŸ’¡ **Why this result?** We used Content-Based filtering to match your Major, then applied a Random Forest Model to predict your success likelihood based on Age and Engagement history.")

else:
    st.write("ðŸ‘ˆ Please enter profile details and click 'Get Recommendations'")